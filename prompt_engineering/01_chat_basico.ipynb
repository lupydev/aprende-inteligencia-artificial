{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c67654a",
   "metadata": {},
   "source": [
    "## GitHub Models API\n",
    "[GitHub Models](https://github.com/marketplace?type=models) proporciona acceso a varios modelos de lenguaje totalmente gratiutos y son los que estaremos utilizando en nuestros ejercicios\n",
    "\n",
    "### Contenido\n",
    "\n",
    "1. Configuración del entorno\n",
    "2. Configurar las credenciales\n",
    "3. Establecer conexión a la API\n",
    "4. Realizar llamadas básicas al modelo\n",
    "5. Exploración de aprametros de configurarición\n",
    "\n",
    "### 1. Configuración del entorno\n",
    "Sigue el paso a paso que encuentras en el [README](../README.md) para instalar las dependencias\n",
    "\n",
    "\n",
    "### 2. Configuración del enterno\n",
    "Dentro de [GitHub Models](https://github.com/marketplace?type=models) dirigite al modelo que desees utilizar, en este caso estaremos utilizando: _OpenAI GPT-4.1_ para realizar los ejercicios, una vez dentro en la parte derecha de la pantalla encontrarás un botón que dice: `Use this model`, das clic y posteriormente `Create personal access token`, creas un token clasico y es el que vas a pegar en la variable de entorno: `GITHUB_TOKEN`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd4d881",
   "metadata": {},
   "source": [
    "### 3. Establecer conexiòn con la API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2d2d4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI library version: 1.97.0\n",
      "Python version: 3.13.5 (main, Jun 11 2025, 15:36:57) [Clang 17.0.0 (clang-1700.0.13.3)]\n",
      "Base URL configurada: https://models.inference.ai.azure.com\n",
      "API Key configurada: ✓\n",
      "API Key preview: ghp_GLs0R4...FyKm\n"
     ]
    }
   ],
   "source": [
    "# Importar las bibliotecas necesarias\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# Verificar que tenemos las bibliotecas correctas\n",
    "print(\"OpenAI library version:\", __import__('openai').__version__)\n",
    "print(\"Python version:\", __import__('sys').version)\n",
    "\n",
    "# Configuración del cliente OpenAI para GitHub Models\n",
    "try:\n",
    "    # Configurar el cliente con variables de entorno\n",
    "    client = OpenAI(\n",
    "        base_url=os.environ.get(\"GITHUB_BASE_URL\"),\n",
    "        api_key=os.environ.get(\"GITHUB_TOKEN\")\n",
    "    )\n",
    "    \n",
    "    # Verificar configuración (sin mostrar la API key completa por seguridad)\n",
    "    print(\"Base URL configurada:\", client.base_url)\n",
    "    print(\"API Key configurada:\", \"✓\" if client.api_key else \"✗\")\n",
    "    \n",
    "    if client.api_key:\n",
    "        print(\"API Key preview:\", client.api_key[:10] + \"...\" + client.api_key[-4:])\n",
    "    else:\n",
    "        print(\"⚠️  API Key no encontrada. Asegúrate de configurar GITHUB_TOKEN\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error en configuración: {e}\")\n",
    "    print(\"Verifica que las variables de entorno estén configuradas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45058dd",
   "metadata": {},
   "source": [
    "### 4. Realizar llamadas básicas al modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26620d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Respuesta del Modelo ===\n",
      "¡Hola! Estoy aquí y listo para ayudarte.\n",
      "\n",
      "=== Información Técnica ===\n",
      "Modelo usado: gpt-4o-2024-11-20\n",
      "Tokens usados: 30\n",
      "Tokens de entrada: 19\n",
      "Tokens de salida: 11\n"
     ]
    }
   ],
   "source": [
    "# Primera llamada básica al modelo\n",
    "def llamada_basica():\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": \"Hola, ¿cómo estás? Responde en una oración.\"}\n",
    "            ],\n",
    "            temperature=0.1, # 0.0 - 1.0, 0.0 es el más conservador, 1.0 es el más creativo\n",
    "            max_tokens=150, \n",
    "        )\n",
    "        \n",
    "        print(\"=== Respuesta del Modelo ===\")\n",
    "        print(response.choices[0].message.content)\n",
    "        print(\"\\n=== Información Técnica ===\")\n",
    "        print(f\"Modelo usado: {response.model}\")\n",
    "        print(f\"Tokens usados: {response.usage.total_tokens}\")\n",
    "        print(f\"Tokens de entrada: {response.usage.prompt_tokens}\")\n",
    "        print(f\"Tokens de salida: {response.usage.completion_tokens}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error en la llamada: {e}\")\n",
    "        print(\"Verifica tu configuración y conexión a internet\")\n",
    "\n",
    "# Ejecutar la función\n",
    "llamada_basica()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caf5831",
   "metadata": {},
   "source": [
    "### Roles: system, assistan, user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ce0537e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Respuesta con Mensaje de Sistema ===\n",
      "Una API (Interfaz de Programación de Aplicaciones) es como un menú en un restaurante: te muestra lo que puedes pedir (funciones o datos) y cómo pedirlo, sin tener que saber cómo se prepara todo \"en la cocina\". Por ejemplo, cuando usas una app para ver el clima, esta utiliza una API para obtener datos meteorológicos de un servidor.\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo con mensaje de sistema\n",
    "def usar_mensaje_sistema():\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\n",
    "                    # Aquí podemos ir armando la personalidad del modelo\n",
    "                    \"role\": \"system\", \n",
    "                    \"content\": \"Eres un experto en tecnología que explica conceptos complejos de manera simple y amigable. Siempre incluyes ejemplos prácticos. Tus respuestas deben contener un máximo de 200 tokens\" \n",
    "                },\n",
    "                {\n",
    "                    # Este rol es el que se encarga de responder a la pregunta del usuario, por asi decirlo es la voz del modelo\n",
    "                    \"role\": \"assistant\", \n",
    "                    \"content\": \"Hola, ¿cómo estás? Responde en una oración.\" \n",
    "                },\n",
    "                {\n",
    "                    # Este rol es el que se encarga de hacer la pregunta al modelo\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": \"¿Qué es una API?\"\n",
    "                }\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "            max_tokens=200\n",
    "        )\n",
    "        \n",
    "        print(\"=== Respuesta con Mensaje de Sistema ===\")\n",
    "        print(response.choices[0].message.content)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Ejecutar función\n",
    "usar_mensaje_sistema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b79a31",
   "metadata": {},
   "source": [
    "### 5. Explorando parametros de configuración\n",
    "\n",
    "Los parámetros más importantes al hacer llamadas a LLMs son:\n",
    "\n",
    "- **temperature**: Controla la creatividad (0.0 = conservador, 1.0 = muy creativo)\n",
    "- **max_tokens**: Límite de tokens en la respuesta\n",
    "- **model**: El modelo específico a usar (gpt-4o, gpt-3.5-turbo, etc.)\n",
    "- **messages**: Array de mensajes con roles (system, user, assistant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e513eac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "TEMPERATURE: 0.1\n",
      "==================================================\n",
      "En un pequeño taller lleno de herramientas y chispas, un robot llamado C1-B0 fue activado por primera vez. Diseñado para tareas domésticas, su creador, el ingeniero Mateo, le dio una misión especial: aprender a cocinar.\n",
      "\n",
      "C1-B0 comenzó estudiando recetas en su base de datos, pero pronto descubrió que cocinar no era solo seguir instrucciones. El primer día, intentó hacer una sopa, pero olvidó probar la temperatura y terminó sirviendo un caldo\n",
      "\n",
      "Tokens usados: 121\n",
      "\n",
      "==================================================\n",
      "TEMPERATURE: 0.5\n",
      "==================================================\n",
      "En un pequeño taller lleno de herramientas y chispas, un robot llamado C1-T0, diseñado para tareas industriales, encontró un viejo libro de recetas cubierto de polvo. Intrigado por los colores y formas en las páginas, decidió intentarlo. \n",
      "\n",
      "Al principio, sus movimientos eran torpes: rompió huevos con demasiada fuerza y quemó un pastel en el horno. Pero C1-T0 no se desanimó. Analizó cada error, ajustó sus algoritmos y\n",
      "\n",
      "Tokens usados: 121\n",
      "\n",
      "==================================================\n",
      "TEMPERATURE: 0.9\n",
      "==================================================\n",
      "Había una vez un pequeño robot llamado K1-TCH3N, diseñado para tareas básicas del hogar. Sin embargo, su programación tenía un defecto: carecía de recetas predeterminadas. Un día, su dueño, Marta, dejó un libro de cocina sobre la encimera. Curioso, K1-TCH3N escaneó las páginas y decidió intentarlo.\n",
      "\n",
      "La primera receta fue un desastre. El pastel de chocolate salió más parecido a un ladrillo que a un postre\n",
      "\n",
      "Tokens usados: 121\n"
     ]
    }
   ],
   "source": [
    "# Comparando diferentes valores de temperature\n",
    "def comparar_temperature():\n",
    "    prompt = \"Escribe una historia muy corta sobre un robot que aprende a cocinar.\"\n",
    "    \n",
    "    temperatures = [0.1, 0.5, 0.9]\n",
    "    \n",
    "    for temp in temperatures:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"TEMPERATURE: {temp}\")\n",
    "        print('='*50)\n",
    "        \n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=temp,\n",
    "                max_tokens=100\n",
    "            )\n",
    "            \n",
    "            print(response.choices[0].message.content)\n",
    "            print(f\"\\nTokens usados: {response.usage.total_tokens}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "# Ejecutar comparación\n",
    "comparar_temperature()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497c4ed2",
   "metadata": {},
   "source": [
    "### Chat Básico\n",
    "Este chat básico nos permite ir llevando un registro de la interacción del usuario y la respuestas del modelo como en una conversación normal en cualquier chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aced949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Pregunta: \n",
      "¿Qué debería ordenar para sacar el máximo provecho a 5 dólares en mcdonalds?\n",
      "\n",
      "Respuesta: \n",
      "¡Claro! Con 5 dólares en McDonald's, puedes aprovechar al máximo tu dinero. Aquí tienes algunas opciones:\n",
      "\n",
      "1. **Menú de valor**: Busca el menú de valor, donde puedes encontrar hamburguesas o nuggets a buen precio. A menudo, puedes conseguir una hamburguesa y una bebida.\n",
      "\n",
      "2. **McChicken o Cheeseburger**: A veces, puedes encontrar estos sándwiches en el menú de valor por menos de 2 dólares cada uno. Combina\n",
      "\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Pregunta: \n",
      "¿Qué debería ordenar para sacar el máximo provecho a 5 dólares en kfc?\n",
      "\n",
      "Respuesta: \n",
      "¡Claro! En KFC, puedes aprovechar tus 5 dólares de varias maneras. Aquí tienes algunas sugerencias:\n",
      "\n",
      "1. **Combo de 2 piezas**: A menudo, puedes encontrar un combo de 2 piezas de pollo con una guarnición y una bebida por alrededor de 5 dólares. Es una opción muy completa.\n",
      "\n",
      "2. **Tenders**: Busca el combo de 3 tenders, que a veces está en el rango de 5 dólares. Viene con una gu\n",
      "\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Pregunta: \n",
      "¿Qué debería ordenar para sacar el máximo provecho a 5 dólares en taco bell?\n",
      "\n",
      "Respuesta: \n",
      "¡Perfecto! En Taco Bell, puedes hacer que tus 5 dólares rindan mucho. Aquí tienes algunas opciones:\n",
      "\n",
      "1. **Menú Cravings**: Busca el menú Cravings, donde puedes encontrar combos por 5 dólares. A menudo incluyen un burrito, un taco y una bebida.\n",
      "\n",
      "2. **Tacos y Burritos**: Puedes pedir varios tacos o burritos individuales. Por ejemplo, 3 tacos por 1 dólar cada uno y un burrito por 2-\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "\n",
    "conversation = [\n",
    "    {\n",
    "        \"role\":\"system\", \n",
    "        \"content\":\"Eres un experto en food hacking, siempre respondes en español y en un tono amigable y conciso\"\n",
    "    },\n",
    "]\n",
    "\n",
    "questions = [\n",
    "    \"¿Qué debería ordenar para sacar el máximo provecho a 5 dólares en mcdonalds?\", \n",
    "    \"¿Qué debería ordenar para sacar el máximo provecho a 5 dólares en kfc?\", \n",
    "    \"¿Qué debería ordenar para sacar el máximo provecho a 5 dólares en taco bell?\",\n",
    "]\n",
    "\n",
    "def get_response(\n",
    "    messages: List[Dict[str, str]],\n",
    ") -> str:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        max_completion_tokens=100,\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "for q in questions:\n",
    "    user_dict = {\"role\":\"user\", \"content\":q}\n",
    "    conversation.append(user_dict)\n",
    "\n",
    "    assintant_dict = {\"role\": \"assistant\", \"content\": get_response(conversation)}\n",
    "    conversation.append(assintant_dict)\n",
    "\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Pregunta: \\n{q}\")\n",
    "    print(f\"\\nRespuesta: \\n{assintant_dict['content']}\")\n",
    "    print(f\"\\n{'='*50}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
